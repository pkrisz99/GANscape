# GANscape
**Image inpainting** tool specialised for **landscape** pictures, utilizing the power of **deep learning** and **generative adversarial networks**. Developed for Deep Learning in Practice at **Budapest University of Technology and Economics** in Autumn 2020.

## Steps for compiling the databank
- We downloaded the **Places2** 256x256 train database from http://places2.csail.mit.edu/download.html
- Out of the about 1.8 million images, 244k were from categories, that we considered potentially useful.
- The YOLOv3 neural network was used to exclude images that contained people. We did this by distributing files into smaller folders, so that can be run on Colaboratory, but we used our CPU's as well. A batch of 10k images took about 4 hours to process.
- This left us with 203k good images, which we separated into train, test, and validation datasets.
- We used a 5% testing and a 10% validation split.
- An other script was used to cut out parts of the images. The original images, the cut out parts and the modified images were all saved, along with the coordinates of the cut out parts.
- Finally this left us with 3x203k images, with a total size of 5.4 gigabytes.

## Databank modifications in order to optimize the data for the network
- Having the 256x256 database created before, we use this as a strating point, and our frist step is to make it 64x64 so we could use data that require less space
- We set the crop sizes from 20x20 to 25x25 which means 10-15% of the area of the picure will be cropped
- Around these crops we set a unifrom 28x28 rectangle. This was important, because the one of the netwrok's inputs is the cropped part, therefore we need a part on every picture that has the same dimensions.
- The test and validation spilt stayed the same
- So at the this left us with 3x203k images, with a total size of 807 Megabytes

## dataloading class
- In order to make the loading in of the pictures smooth, we made an individual class for this purpose
- DataRead class stores the needed data for the training 
- Further information about this is class is in the doc folder

## Constructing the network
- While constructing the network we relied heavily on the article: http://iizuka.cs.tsukuba.ac.jp/projects/completion/data/completion_sig2017.pdf and also on the implementation of a netwrok based on this article: https://github.com/V1NAY8/glcic
- Our network has a GAN structure as it has a generator and a discriminator part
- The generator gets the cropped image and tries to generate the missing part od the picture
- The discriminator gets the generated picture and also individually the part that needed to generated, in our netwrok this is 64x64 picture and a  28x28 cropped part. With the given inputs the discriminator tries to determine whether the picture is generated by the generator or not
- The training of the network is made of three parts. First we train the generator with MSE loss, then we train the discriminator individually with generated and also not generated pictures with a binary crossentropy loss, and finally we train the generator and discriminator together with the discriminators weights locked with a joint loss, for the generator to be able to fool the discriminator.


## Links for the databank

**Disclaimer**: We do not intend to distribute this database, we are only providing these for educational evaluation purposes.

Link for the data with the chosen classes:(not available anymore)
https://drive.google.com/file/d/15SSnj3CllTz_73jKHOVU-9HpYgRpxAYm/view?usp=sharing

Link for the data with only train data:
https://drive.google.com/file/d/1WGVtHwXxGNojM5xvq0EinaTX_q-o_rUA/view?usp=sharing

Link for the data with train, validation and test data:
https://drive.google.com/file/d/15Y-wFgWVc06hFLslSP_ABl3cr-LPMwOQ/view?usp=sharing

Link for the data with the 64x64 pictures:(not available anymore)
https://drive.google.com/file/d/1mkQG3OeBWKsnZNwciwP6k0wGEAoVUMTM/view?usp=sharing

Link for the data with the 64x64 pictures that have 28x28 cropped parts:
https://drive.google.com/file/d/1_RrWfKYkiXOKfmU8UxtWFqMNqNKQtQGF/view?usp=sharing
