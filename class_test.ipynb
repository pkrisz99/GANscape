{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataread import DataRead\n",
    "#important parts\n",
    "# self.batch_num\n",
    "# self.batch_size\n",
    "# self.target_images eredeti kép\n",
    "# self.cropped_images kivágott kép\n",
    "# self.crop_images kivágott rész\n",
    "# self.result_images majd ide lehet tenni a háló kimenetelét\n",
    "# self.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172703\n",
      "172703\n",
      "172703\n"
     ]
    }
   ],
   "source": [
    "train = DataRead(r'C:\\\\places\\\\','train',1,5)#path, mode, batch size, batch num  folder_path, data_type, batch_size, batch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1, 64, 64, 3)\n",
      "(5, 1, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.target_images.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1, 64, 64, 4)\n",
      "(5, 1, 64, 64, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train.cropped_images.shape)\n",
    "train.make_masks()\n",
    "print(train.cropped_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23, 3, 48, 27, 22, 1, 49, 28]]\n"
     ]
    }
   ],
   "source": [
    "print(train.csv[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 25, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.result_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172703\n",
      "172703\n",
      "172703\n"
     ]
    }
   ],
   "source": [
    "train.reset() #újra tölti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "63 63\n",
      "(5, 25, 64, 64, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(train.cropped_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106, 39, 197, 106]\n",
      "[145, 118, 233, 191]\n",
      "[146, 85, 231, 151]\n",
      "[140, 134, 207, 212]\n",
      "[53, 104, 139, 202]\n",
      "[42, 81, 129, 161]\n",
      "[101, 95, 170, 171]\n",
      "[147, 42, 234, 132]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"out_train.csv\", \"r\") as infile:\n",
    "    r = csv.reader(infile)\n",
    "    for i in range(8): # count from 0 to 7\n",
    "        row = next(r)\n",
    "        row = row[1:]\n",
    "        row = list(map(int, row))\n",
    "        print(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test = np.ones((4,3))\n",
    "print(test)\n",
    "test = np.pad(test,((3,1),(2,1)))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test = np.ones((4,4,3))\n",
    "insert = np.ones((1,2))\n",
    "insert = np.pad(insert,((2,1),(1,1)))\n",
    "print(insert)\n",
    "print(test)\n",
    "test = np.insert(test, 3, insert, axis=2)\n",
    "#print(test.shape)\n",
    "#print(test)\n",
    "print(test[:,:,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test = np.ones((3,4,2,2,1))\n",
    "insert = np.zeros((3,4,2,2))\n",
    "\n",
    "test = np.insert(test, 1, insert, axis=4)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self, pic_size):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.c1_1 = tf.keras.layers.Conv2D(8,3,input_shape=(pic_size, pic_size, 4),activation='relu',padding=\"same\")\n",
    "        self.c1_2 = tf.keras.layers.Conv2D(16,3,activation='relu',padding=\"same\")\n",
    "        \n",
    "        self.p1 = tf.keras.layers.Conv2D(32,3,strides=2,activation='relu',padding=\"same\")\n",
    "        self.p2 = tf.keras.layers.Conv2D(64,3,strides=2,activation='relu',padding=\"same\")\n",
    "        \n",
    "        self.c2_1 = tf.keras.layers.Conv2D(128,3,activation='relu',padding=\"same\")\n",
    "        self.c2_2 = tf.keras.layers.Conv2D(128,3,activation='relu',padding=\"same\")\n",
    "        \n",
    "        self.p3 = tf.keras.layers.Conv2DTranspose(64,3, strides=2,activation='relu',padding=\"same\")\n",
    "        self.p4 = tf.keras.layers.Conv2DTranspose(32,3, strides=2,activation='relu',padding=\"same\")\n",
    "        \n",
    "        self.c3_1 = tf.keras.layers.Conv2D(16,3,activation='relu',padding=\"same\")\n",
    "        self.c3_2 = tf.keras.layers.Conv2D(3,3,activation='relu',padding=\"same\")\n",
    "        \n",
    "        \n",
    "    def call(self, inp, pic_size):\n",
    "        x = inp\n",
    "        mask = inp[0,:,:,3]\n",
    "        \n",
    "        \n",
    "        x=self.c1_1(x)\n",
    "        x=self.c1_2(x)\n",
    "        \n",
    "        x=self.p1(x)\n",
    "        x=self.p2(x)\n",
    "        \n",
    "        x=self.c2_1(x)\n",
    "        x=self.c2_2(x)\n",
    "        \n",
    "        x=self.p3(x)\n",
    "        x=self.p4(x)\n",
    "        \n",
    "        x=self.c3_1(x)\n",
    "        x=self.c3_2(x)\n",
    "        \n",
    "        #x =tf.math.multiply(x*mask)\n",
    "        # x [batch_size, x,y,3]\n",
    "        print(x.shape)\n",
    "        \n",
    "        whole = inp\n",
    "        \n",
    "        #whole = tf.convert_to_tensor(inp)\n",
    "        #whole = x[]\n",
    "        crop = x[0,10:20+1, 10:20+1,:]\n",
    "        #crop = whole[1,pic_size[4]:pic_size[6]+1, pic_size[5]:pic_size[7]+1,3]\n",
    "        whole[0,10:20+1, 10:20+1,:]  = crop\n",
    "        crop = whole[0,10:23+1, 10:23+1,:] \n",
    "        \n",
    "        return whole, crop\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method CNN.call of <__main__.CNN object at 0x0000022C76ABFB48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method CNN.call of <__main__.CNN object at 0x0000022C76ABFB48>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method CNN.call of <__main__.CNN object at 0x0000022C76ABFB48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method CNN.call of <__main__.CNN object at 0x0000022C76ABFB48>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "(1, 64, 64, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-73-0f36d5946b47>:53 call\n        whole[0,10:20+1, 10:20+1,:]  = crop\n\n    TypeError: 'Tensor' object does not support item assignment\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-760480b97a1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcropped_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m                   \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-73-0f36d5946b47>:53 call\n        whole[0,10:20+1, 10:20+1,:]  = crop\n\n    TypeError: 'Tensor' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "network = CNN(64)\n",
    "predictions = network(train.cropped_images[0],train.csv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_10:0\", shape=(10,), dtype=float64)\n",
      "(5, 1, 64, 64, 4)\n",
      "(64, 64)\n",
      "(3, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tensor = tf.convert_to_tensor(train.cropped_images[0])\n",
    "print(tensor[0,0:10,0,1])\n",
    "\n",
    "print(train.cropped_images.shape)\n",
    "mask = train.cropped_images[0,0,:,:,3]\n",
    "print(mask.shape)\n",
    "masks = np.array([[mask],[mask],[mask]])\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.backend.ones((16, 64))\n",
    "y = tf.keras.backend.ones((64, 16))\n",
    "xy = tf.keras.backend.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_schedule= tf.keras.optimizers.schedules.ExponentialDecay(1e-5, decay_steps=10000, decay_rate=0.5,staircase=True)#====\n",
    "#lr_schedule= tf.keras.optimizers.schedules.InverseTimeDecay(1e-5, decay_steps=3000, decay_rate=9,staircase=True)#====\n",
    "\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.98, epsilon=1e-9, )#======\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9, )\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    #return tf.reduce_mean(tf.math.square(real-pred))  #========\n",
    "    return tf.reduce_sum(tf.math.square(real-pred))\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = CNN3(in_seq_len,input_size,target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "'''\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Checkpoint restored\")\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step_signature =  [\n",
    "    tf.TensorSpec(shape=(None, None, input_size), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None, 1, target_size), dtype=tf.float32)\n",
    "    ]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = transformer(inp)\n",
    "\n",
    "        \n",
    "        loss = loss_function(tar, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    #optimizer.step()\n",
    "    \n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and feedback\n",
    "losses=[]\n",
    "#======\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    stime = time.time()\n",
    "    \n",
    "    xp=0 #=======\n",
    "    yp=0\n",
    "    zp=0\n",
    "    tp=0\n",
    "    w=0\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    h=0\n",
    "    for batch in range(X.shape[0]):\n",
    "        inp = X[batch]\n",
    "        tar = Y[batch]\n",
    "        \n",
    "        #========\n",
    "        xprec, yprec, zprec, truprec, whole = precision_function(inp, tar, 0.005)\n",
    "        xp+=xprec\n",
    "        yp+=yprec\n",
    "        zp+=zprec\n",
    "        tp+=truprec\n",
    "        w+=whole\n",
    "        \n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        if batch % 50 ==0:\n",
    "            print('Epoch {} Batch {} Loss {:.5f}'.format(\n",
    "            epoch+1, batch, train_loss.result()\n",
    "            ))\n",
    "            \n",
    "    \n",
    "    print('Epoch {} Precisions: x:{:.2f} %, y:{:.2f} %, z:{:.2f} %'.format(epoch+1, xp/w*100 , yp/w*100, zp/w*100)) #========\n",
    "    print('Epoch {} True Precisions: {:.2f} %'.format(epoch+1, tp/w*100)) \n",
    "    \n",
    "    if (epoch+1) %5 ==0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "   \n",
    "    \n",
    "    print ('Epoch {} Loss {:.5f}'.format(epoch + 1,  train_loss.result()))\n",
    "    losses.append(train_loss.result())#=====\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - stime))\n",
    "#========\n",
    "timel=np.arange(epochs)+1\n",
    "plt.plot(timel,losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
